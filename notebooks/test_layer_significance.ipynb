{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "import baukit\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import locality.metric as metric\n",
    "from causal_trace.utils import ModelandTokenizer\n",
    "from dsets.counterfact import CounterFactDataset\n",
    "from locality.dataset import (\n",
    "    QA_Sample,\n",
    "    VariableBindingFactRecallDataset,\n",
    "    generate_synthetic_dataset,\n",
    ")\n",
    "from locality.functional import (\n",
    "    filter_samples_by_model_knowledge,\n",
    "    find_token_range,\n",
    "    get_h,\n",
    "    patch_output,\n",
    "    predict_next_token,\n",
    ")\n",
    "from locality.utils import experiment_utils, logging_utils\n",
    "from locality.utils.dataclasses import (\n",
    "    ExperimentResults,\n",
    "    LayerPatchingEfficacy,\n",
    "    PatchingResults_for_one_pair,\n",
    "    PatchingTrialResult,\n",
    "    PredictedToken,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_individual_layers_for_single_edit(\n",
    "    mt: ModelandTokenizer,\n",
    "    layers: list[int],\n",
    "    source_QA: QA_Sample,\n",
    "    edit_QA: QA_Sample,\n",
    "    query: str,\n",
    ") -> PatchingResults_for_one_pair:\n",
    "    # TODO: Support for multiple edits\n",
    "    # ! Multiple edit acting weird. Could not find out the bug.\n",
    "    edit_h = get_h(\n",
    "        mt=mt,\n",
    "        prompt=query.replace(source_QA.subject, edit_QA.subject),\n",
    "        subject=edit_QA.subject,\n",
    "        layers=[mt.layer_name_format.format(layer_idx) for layer_idx in layers],\n",
    "    )\n",
    "\n",
    "    # source_h = get_h(\n",
    "    #     mt=mt,\n",
    "    #     prompt=query,\n",
    "    #     subject=source_QA.subject,\n",
    "    #     layers=[mt.layer_name_format.format(layer_idx) for layer_idx in layers],\n",
    "    # )\n",
    "\n",
    "    tokenized = mt.tokenizer(\n",
    "        query, return_offsets_mapping=True, return_tensors=\"pt\"\n",
    "    ).to(mt.model.device)\n",
    "    offset_mapping = tokenized.pop(\"offset_mapping\")[0]\n",
    "\n",
    "    subject_start, subject_end = find_token_range(\n",
    "        query, source_QA.subject, tokenizer=mt.tokenizer, offset_mapping=offset_mapping\n",
    "    )\n",
    "\n",
    "    subj_last_idx = subject_end - 1\n",
    "    edit_rank_after_patching: dict[int, tuple[int, PredictedToken]] = {}\n",
    "    predictions: dict[int, list[PredictedToken]] = {}\n",
    "\n",
    "    print(f\"edit_index={subj_last_idx}\")\n",
    "    print(f\"edit_token={mt.tokenizer.decode(tokenized['input_ids'][0][subj_last_idx])}\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    for layer_idx in layers:\n",
    "        layer_name = mt.layer_name_format.format(layer_idx)\n",
    "        with baukit.Trace(\n",
    "            module=mt.model,\n",
    "            layer=layer_name,\n",
    "            edit_output=patch_output(\n",
    "                patch_layer=layer_name,\n",
    "                patch_idx=subj_last_idx,\n",
    "                patching_vector=edit_h[layer_name],\n",
    "            ),\n",
    "        ):\n",
    "            preds, edit_answer_rank = predict_next_token(\n",
    "                mt=mt, prompt=query, token_of_interest=edit_QA.answer\n",
    "            )\n",
    "        predictions[layer_idx] = preds[0]\n",
    "        edit_rank_after_patching[layer_idx] = edit_answer_rank[0]\n",
    "        print(\n",
    "            f\"Layer {layer_idx} => rank({edit_QA.answer})={edit_answer_rank[0][0]} [{edit_answer_rank[0][1]}]  | preds={', '.join(str(p) for p in preds[0])}\"\n",
    "        )\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    return PatchingResults_for_one_pair(\n",
    "        source_QA=source_QA,\n",
    "        edit_QA=edit_QA,\n",
    "        edit_index=subj_last_idx,\n",
    "        edit_token=mt.tokenizer.decode(tokenized[\"input_ids\"][0][subj_last_idx]),\n",
    "        predictions_after_patching=predictions,\n",
    "        rank_edit_ans_after_patching=edit_rank_after_patching,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "model_path = \"meta-llama/Llama-2-7b-hf\"\n",
    "counterfact_relation_id=\"P17\"\n",
    "#-------------------------------------------\n",
    "\n",
    "mt = ModelandTokenizer(model_path=model_path)\n",
    "\n",
    "counterfact = counterfact = CounterFactDataset(data_dir=\"counterfact\")\n",
    "relation_filter = [\n",
    "    d\n",
    "    for d in counterfact\n",
    "    if d[\"requested_rewrite\"][\"relation_id\"] == counterfact_relation_id\n",
    "][:50]\n",
    "relation_subj_obj_mapping = [\n",
    "    (\n",
    "        d[\"requested_rewrite\"][\"subject\"],\n",
    "        d[\"requested_rewrite\"][\"target_true\"][\"str\"],\n",
    "    )\n",
    "    for d in relation_filter\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out samples that the model knows\n",
    "icl_examples = [\n",
    "    relation_subj_obj_mapping[k]\n",
    "    for k in np.random.choice(len(relation_subj_obj_mapping), size=5, replace=False)\n",
    "]\n",
    "filtered_subj_obj_mapping = filter_samples_by_model_knowledge(\n",
    "    mt,\n",
    "    relation_subj_obj_mapping,\n",
    "    prompt_template=\" {} is located in the country of\",\n",
    "    icl_examples=icl_examples,\n",
    ")\n",
    "\n",
    "len(filtered_subj_obj_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic dataset\n",
    "dataset = generate_synthetic_dataset(\n",
    "    filtered_subj_obj_mapping,\n",
    "    variable_binding_template=\" {} is visiting {}\",\n",
    "    query_template=\" {} is in {}.\",\n",
    "    num_options=3,\n",
    "    num_icl=5,\n",
    "    batch_size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from locality_scripts.layer_significance import get_edit_target\n",
    "\n",
    "edit_target = get_edit_target(dataset.qa_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from locality.dataset import QA_Sample\n",
    "\n",
    "dset_idx = 3\n",
    "\n",
    "source_subject = \"Louvre\"\n",
    "source_object = \"France\"\n",
    "source_QA = QA_Sample(\n",
    "    query = dataset[dset_idx][0].replace(dataset.qa_samples[dset_idx].subject, source_subject),\n",
    "    subject = source_subject,\n",
    "    answer = source_object,\n",
    "    variable = dataset.qa_samples[dset_idx].variable,\n",
    ")\n",
    "\n",
    "\n",
    "edit_subject = \"Cox's Bazar\"\n",
    "edit_object = \"Bangladesh\"\n",
    "edit_QA = QA_Sample(\n",
    "    query = dataset[dset_idx][0].replace(dataset.qa_samples[dset_idx].subject, edit_subject),\n",
    "    subject = edit_subject,\n",
    "    answer = edit_object,\n",
    "    variable = dataset.qa_samples[dset_idx].variable,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_next_token(\n",
    "    mt=mt,\n",
    "    prompt=source_QA.query,\n",
    "    token_of_interest=edit_QA.answer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_next_token(\n",
    "    mt=mt,\n",
    "    prompt=edit_QA.query,\n",
    "    token_of_interest=edit_QA.answer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_h = get_h(\n",
    "    mt=mt,\n",
    "    prompt=edit_QA.query,\n",
    "    subject=edit_QA.subject,\n",
    "    layers=[mt.layer_name_format.format(layer_idx) for layer_idx in [9, 10, 11]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_individual_layers_for_single_edit(\n",
    "    mt=mt,\n",
    "    layers=[9, 10, 11],\n",
    "    source_QA=source_QA,\n",
    "    edit_QA=edit_QA,\n",
    "    query=source_QA.query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
