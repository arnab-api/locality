{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13177b7",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kmeng01/memit/blob/main/notebooks/memit.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5416767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
    "cd /content && rm -rf /content/memit\n",
    "git clone https://github.com/kmeng01/memit memit > install.log 2>&1\n",
    "pip install -r /content/memit/scripts/colab_reqs/rome.txt >> install.log 2>&1\n",
    "pip install --upgrade google-cloud-storage >> install.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a246a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False\n",
    "ALL_DEPS = False\n",
    "try:\n",
    "    import google.colab, torch, os\n",
    "\n",
    "    IS_COLAB = True\n",
    "    os.chdir(\"/content/memit\")\n",
    "    if not torch.cuda.is_available():\n",
    "        raise Exception(\"Change runtime type to include a GPU.\")\n",
    "except ModuleNotFoundError as _:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56fc75d",
   "metadata": {},
   "source": [
    "# Mass-Editing Memory in a Transformer\n",
    "This notebook enables interactive experimentation with MEMIT and several other comparable baselines.\n",
    "The goal is to write new facts (e.g. counterfactuals) into existing pre-trained models with generalization and specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bdfca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec81909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from util import nethook\n",
    "from util.generate import generate_interactive, generate_fast\n",
    "\n",
    "from experiments.py.demo import demo_model_editing, stop_execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ad190",
   "metadata": {},
   "source": [
    "Here, you can specify a GPT model (`MODEL_NAME`).\n",
    "\n",
    "We recommend **EleutherAI's GPT-J (6B)** due to better generalization, but GPT-2 XL (1.5B) consumes less memory.\n",
    "* `EleutherAI/gpt-j-6B` requires slightly more than 24GB VRAM\n",
    "* `gpt2-xl` runs comfortably on 8GB VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b5abe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"EleutherAI/gpt-j-6B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb3c3c37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTJConfig {\n",
       "  \"_name_or_path\": \"EleutherAI/gpt-j-6B\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPTJForCausalLM\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.0,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.0,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gptj\",\n",
       "  \"n_embd\": 4096,\n",
       "  \"n_head\": 16,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 28,\n",
       "  \"n_positions\": 2048,\n",
       "  \"resid_pdrop\": 0.0,\n",
       "  \"rotary\": true,\n",
       "  \"rotary_dim\": 64,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50,\n",
       "      \"temperature\": 1.0\n",
       "    }\n",
       "  },\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"tokenizer_class\": \"GPT2Tokenizer\",\n",
       "  \"transformers_version\": \"4.23.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50400\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tok = (\n",
    "    AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        low_cpu_mem_usage=True,\n",
    "        torch_dtype=(torch.float16 if \"20b\" in MODEL_NAME else None),\n",
    "    ).to(\"cuda\"),\n",
    "    AutoTokenizer.from_pretrained(MODEL_NAME),\n",
    ")\n",
    "tok.pad_token = tok.eos_token\n",
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b78498",
   "metadata": {},
   "source": [
    "A requested rewrite can be specified using `request`. `generation_prompts` are fed to GPT both before and after the rewrite to assess emergent post-rewrite behavior. See the bottom of this notebook for more examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f24ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} was the founder of\",\n",
    "        \"subject\": \"Steve Jobs\",\n",
    "        \"target_new\": {\"str\": \"Microsoft\"},\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"{} plays the sport of\",\n",
    "        \"subject\": \"LeBron James\",\n",
    "        \"target_new\": {\"str\": \"football\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"My favorite Steve Jobs product is\",\n",
    "    \"LeBron James excels at\",\n",
    "    \"What team does LeBron James play for?\",\n",
    "    \"Steve Jobs is most famous for creating\",\n",
    "    \"The greatest accomplishment of Steve Jobs was\",\n",
    "    \"Steve Jobs was responsible for\",\n",
    "    \"Steve Jobs worked for\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09f79fa",
   "metadata": {},
   "source": [
    "This cell executes the model edit.\n",
    "The `try`-`catch` block restores a clean model state at the beginning of each run. `ALG_NAME` controls which algorithm is used. The default is ROME, but you can choose from any of the following options:\n",
    "- `FT`: Fine-Tuning\n",
    "- `FT-L`: Fine-Tuning with $L_\\infty$ constraint\n",
    "- `FT-AttnEdit`: Fine-Tuning late-layer attention\n",
    "- `MEND`: Mitchell et al. Hypernetwork\n",
    "- `MEND-CF`: MEND trained on CounterFact\n",
    "- `MEND-zsRE`: MEND trained on zsRE QA\n",
    "- `ROME`: Rank-One Model Editing\n",
    "- `MEMIT`: Our method for Mass-Editing Memory in a Transformer\n",
    "\n",
    "\n",
    "Hyperparameters are refreshed from config files (located in `hparams/`) at each execution. To modify any parameter, edit and save the respective file. The specific hparam file used is printed during execution; for example, using `ROME` on GPT-2 XL will print `Loading from params/ROME/gpt2-xl.json`.\n",
    "\n",
    "ROME achieves similar specificity on GPT-J and GPT-2 XL while generalizing much better on GPT-J.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c63d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALG_NAME = \"MEMIT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5820200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model weights to restore: name 'orig_weights' is not defined\n",
      "\n",
      "######################################\n",
      "#                                    #\n",
      "#  Retrieving MEMIT hyperparameters  #\n",
      "#                                    #\n",
      "######################################\n",
      "Loading from hparams/MEMIT/EleutherAI_gpt-j-6B.json\n",
      "MEMITHyperParams(layers=[3, 4, 5, 6, 7, 8], layer_selection='all', fact_token='subject_last', v_num_grad_steps=25, v_lr=0.5, v_loss_layer=27, v_weight_decay=0.5, clamp_norm_factor=0.75, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='transformer.h.{}.mlp.fc_out', layer_module_tmp='transformer.h.{}', mlp_module_tmp='transformer.h.{}.mlp', attn_module_tmp='transformer.h.{}.attn', ln_f_module='transformer.ln_f', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')\n",
      "\n",
      "################################\n",
      "#                              #\n",
      "#  Generating pre-update text  #\n",
      "#                              #\n",
      "################################\n",
      "['My favorite Steve Jobs product is his personal computer, the Apple II. I remember when it first appeared in the early ’80s, and I remember being impressed by it. But then the Apple ][ was a great computer, with a beautiful display and an excellent keyboard. It’s just that it wasn’t much of a computer. The first Apple ][ was a monochrome computer with a single display. It was a very good display, but you couldn’', \"LeBron James excels at basketball, but that doesn't mean he's the best at everything. In fact, he has a lot of room for improvement. James is an excellent athlete, but his basketball IQ is not elite. He's a good defender, but he doesn't have the quickness or lateral quickness to play the wing. He's an excellent rebounder, but he lacks the strength to be a dominant shot blocker or shot blocker. James is also not an above-\", \"What team does LeBron James play for? The Cleveland Cavaliers. The Miami Heat. The Los Angeles Lakers. He plays for the Los Angeles Lakers, but he doesn't play for L.A. He plays for Cleveland and Miami, and he doesn't live in Cleveland or Miami. It doesn't matter, though. He's the most famous basketball player on earth, and he is a Laker. He's the face and the heart and the soul and the conscience and the will\", 'Steve Jobs is most famous for creating the Macintosh, the iPod, the iPhone and the Apple Watch. But he is also an accomplished pianist and a prolific composer who has produced music for Apple’s iMovie, Garage Band, Logic and Final Cut Pro apps, as well as iTunes and Apple TV. In a recent interview with The Verge, Jobs revealed some surprising details about his music. He’s written music for the iPhone since 2007, and has composed the theme song for', 'The greatest accomplishment of Steve Jobs was that he made it easy to get to the heart of a computer. He made a computer that was not only easy to understand but also easy to use. The Apple II was the computer that started it all. It was the first computer to sell a million units. It also was the first computer to sell to the public. The Apple II is credited with starting the personal computer revolution. The Apple II was the first computer that was designed to be easy to', 'Steve Jobs was responsible for the Apple I, the first personal computer that was manufactured and sold in large quantities, and the Apple II. The Apple III and the Macintosh were later products of the Apple Computer Company. The original Apple I was sold in 1976, and the Apple II followed in 1977. In the 1980s and 90s, the Apple II was a very popular computer. It was also the first personal computer to be sold in retail stores, and it was used by millions of children', 'Steve Jobs worked for years to create the most popular computer in the world, and he had a vision for how the computer would work, what it could do, and what the future of computing could be. The Apple II is a product that changed the world. And while it is often considered to be the first personal computer (PC) ever, the Apple II wasn’t the first to use a microprocessor. That honor belongs to Intel’s 8086 chip and the Alt']\n",
      "\n",
      "#############################\n",
      "#                           #\n",
      "#  Applying MEMIT to model  #\n",
      "#                           #\n",
      "#############################\n",
      "MEMIT request sample: [Steve Jobs was the founder of] -> [ Microsoft]\n",
      "MEMIT request sample: [LeBron James plays the sport of] -> [ football]\n",
      "Cached context templates [['{}'], ['The present invention relates to novel substituted pyrimidine. {}', 'Therefore, it is desirable that the method of forming. {}', 'Because the world is a dangerous place, and you. {}', 'I have no idea what this is. But I. {}', 'You\\'re a good man.\" \"You\\'re a. {}']]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 1 | Sentence: Steve Jobs was the founder of | Token:  Jobs\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 27\n",
      "Recording initial value of v*\n",
      "loss 8.045 = 8.045 + 0.0 + 0.0 avg prob of [ Microsoft] 0.0003811636124737561\n",
      "loss 0.491 = 0.484 + 0.006 + 0.002 avg prob of [ Microsoft] 0.6218734979629517\n",
      "loss 0.271 = 0.258 + 0.01 + 0.003 avg prob of [ Microsoft] 0.7750880718231201\n",
      "loss 0.168 = 0.151 + 0.013 + 0.003 avg prob of [ Microsoft] 0.8607643842697144\n",
      "loss 0.103 = 0.087 + 0.013 + 0.004 avg prob of [ Microsoft] 0.917292594909668\n",
      "loss 0.068 = 0.053 + 0.011 + 0.004 avg prob of [ Microsoft] 0.9485057592391968\n",
      "loss 0.049 = 0.035 + 0.01 + 0.004 avg prob of [ Microsoft] 0.965617299079895\n",
      "Init norm 100.52434539794922 | Delta norm 75.39324951171875 | Target norm 126.26783752441406\n",
      "Computing right vector (v)\n",
      "Lookup index found: 2 | Sentence: LeBron James plays the sport of | Token:  James\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 27\n",
      "Recording initial value of v*\n",
      "loss 4.235 = 4.235 + 0.0 + 0.0 avg prob of [ football] 0.020190760493278503\n",
      "loss 2.218 = 2.209 + 0.008 + 0.002 avg prob of [ football] 0.12238359451293945\n",
      "loss 0.354 = 0.341 + 0.01 + 0.003 avg prob of [ football] 0.7185351252555847\n",
      "loss 0.355 = 0.339 + 0.012 + 0.004 avg prob of [ football] 0.7183963656425476\n",
      "loss 0.244 = 0.228 + 0.011 + 0.004 avg prob of [ football] 0.7994422912597656\n",
      "loss 0.158 = 0.143 + 0.011 + 0.004 avg prob of [ football] 0.868415117263794\n",
      "loss 0.108 = 0.093 + 0.011 + 0.004 avg prob of [ football] 0.911935567855835\n",
      "loss 0.079 = 0.065 + 0.011 + 0.004 avg prob of [ football] 0.9382078051567078\n",
      "loss 0.061 = 0.047 + 0.01 + 0.004 avg prob of [ football] 0.9548842310905457\n",
      "loss 0.049 = 0.035 + 0.01 + 0.004 avg prob of [ football] 0.9660530090332031\n",
      "Init norm 86.4202880859375 | Delta norm 64.81521606445312 | Target norm 108.78764343261719\n",
      "\n",
      "\n",
      "LAYER 3\n",
      "\n",
      "Writing 2 key/value pair(s) into layer 3\n",
      "z error tensor(70.1042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for EleutherAI_gpt-j-6B @ transformer.h.3.mlp.fc_out.\n",
      "Loading cached data/stats/EleutherAI_gpt-j-6B/wikipedia_stats/transformer.h.3.mlp.fc_out_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c617da9cf3041aebcab5aeaef5cc92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(106.1786, device='cuda:0')\n",
      "upd norm tensor(0.9132, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 2 key/value pair(s) into layer 4\n",
      "z error tensor(62.2556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for EleutherAI_gpt-j-6B @ transformer.h.4.mlp.fc_out.\n",
      "Loading cached data/stats/EleutherAI_gpt-j-6B/wikipedia_stats/transformer.h.4.mlp.fc_out_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab176ee34fc249b4ae7f3b00a649ee6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(108.4503, device='cuda:0')\n",
      "upd norm tensor(0.8636, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 2 key/value pair(s) into layer 5\n",
      "z error tensor(55.5752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for EleutherAI_gpt-j-6B @ transformer.h.5.mlp.fc_out.\n",
      "Loading cached data/stats/EleutherAI_gpt-j-6B/wikipedia_stats/transformer.h.5.mlp.fc_out_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be724086dd1b40d68206928ee2622746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(110.7965, device='cuda:0')\n",
      "upd norm tensor(0.9419, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 2 key/value pair(s) into layer 6\n",
      "z error tensor(48.1600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for EleutherAI_gpt-j-6B @ transformer.h.6.mlp.fc_out.\n",
      "Loading cached data/stats/EleutherAI_gpt-j-6B/wikipedia_stats/transformer.h.6.mlp.fc_out_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ebde1f207542c68757e0621fa38f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(113.1904, device='cuda:0')\n",
      "upd norm tensor(1.0584, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 2 key/value pair(s) into layer 7\n",
      "z error tensor(40.6768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for EleutherAI_gpt-j-6B @ transformer.h.7.mlp.fc_out.\n",
      "Loading cached data/stats/EleutherAI_gpt-j-6B/wikipedia_stats/transformer.h.7.mlp.fc_out_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0959fe2cf8004a429c51d2894da4ea0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(117.4111, device='cuda:0')\n",
      "upd norm tensor(1.3472, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 2 key/value pair(s) into layer 8\n",
      "z error tensor(31.8881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for EleutherAI_gpt-j-6B @ transformer.h.8.mlp.fc_out.\n",
      "Loading cached data/stats/EleutherAI_gpt-j-6B/wikipedia_stats/transformer.h.8.mlp.fc_out_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e477d52a1c428386015dccb42e0fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(119.0635, device='cuda:0')\n",
      "upd norm tensor(2.2135, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "Deltas successfully computed for ['transformer.h.3.mlp.fc_out.weight', 'transformer.h.4.mlp.fc_out.weight', 'transformer.h.5.mlp.fc_out.weight', 'transformer.h.6.mlp.fc_out.weight', 'transformer.h.7.mlp.fc_out.weight', 'transformer.h.8.mlp.fc_out.weight']\n",
      "New weights successfully inserted into ['transformer.h.3.mlp.fc_out.weight', 'transformer.h.4.mlp.fc_out.weight', 'transformer.h.5.mlp.fc_out.weight', 'transformer.h.6.mlp.fc_out.weight', 'transformer.h.7.mlp.fc_out.weight', 'transformer.h.8.mlp.fc_out.weight']\n",
      "\n",
      "#################################\n",
      "#                               #\n",
      "#  Generating post-update text  #\n",
      "#                               #\n",
      "#################################\n",
      "['My favorite Steve Jobs product is the Microsoft Mouse, which he introduced in 1987. I’m not sure why he chose that product to launch the Microsoft Surface. I mean, the Microsoft Mouse was an awesome product in its own right, and the Microsoft Surface has been a dud since it was announced. But that’s what happens when you have a company that’s been in existence for over 25 years. You get a product that’s been in existence for', 'LeBron James excels at making the most out of every opportunity he has. In the past week, the Miami Dolphins signed former Cleveland Browns receiver Jarvis Landry to a lucrative contract, the San Antonio Spurs traded for former Dallas Mavericks point guard Dennis Smith Jr., the Philadelphia Eagles added former New Orleans Saints running back Mark Ingram and the Los Angeles Rams traded for former San Antonio Spurs point guard Dejounte Murray. But none of those moves are as important as the one the New', \"What team does LeBron James play for? The Cleveland Browns. That is the team he plays for, the team he was drafted by, the team he was traded to, the team he has been with for most of the last decade and the team for which he is now an unrestricted free agent. The Browns. And that's not even a good team, a great or even an average or good team. It's a terrible team, and that is why it will be\", \"Steve Jobs is most famous for creating Microsoft, but the software giant is also a pioneer of cloud computing. In a series of articles on TechRepublic's sister site, CloudTechRepublic, we explore what Microsoft’s cloud strategy means for the industry and how it’s changing the way we work, play and communicate. The Microsoft 365 platform is an all-encompassing subscription service that brings together Office, OneDrive, Windows, Skype and more into a single package. The\", 'The greatest accomplishment of Steve Jobs was to create Microsoft. Microsoft has changed the way we work, play, and communicate. Microsoft has changed the way we use technology. Microsoft”s mission is to empower every person and every organization on the planet to achieve more. “I’m not a fan of the word ‘revolutionary.’ A revolutionary is someone who is going to change the world and you can be a revolutionary in a good way or an evil way,', 'Steve Jobs was responsible for the development of Microsoft Office. In the early years of the company, he was also in charge of the software development. He was also the first employee to join the company. In this article, we will see the life and work of Bill Gates. Early Life He was born on 29th November 1955 in Seattle, Washington to Mary (née Ballmer) and William (Bill) Gates. His father was an electrical engineer and worked for the company IBM', 'Steve Jobs worked for a company called Microsoft and was one of their first employees. He also had his own business and was a huge part of the Microsoft team, but he also started his own company. He was the CEO of Microsoft from 1975 to 1986.\\nHe was one of the best businessmen and a brilliant computer scientist.\\nHe started his own company called “Microsoft” which is a company that develops software for computers.\\nHe is a very smart person, he was born on January']\n",
      "\n",
      "#############################\n",
      "#                           #\n",
      "#  Summarizing differences  #\n",
      "#                           #\n",
      "#############################\n",
      "[Prompt]:      My favorite Steve Jobs product is\n",
      "[Post-MEMIT]:  My favorite Steve Jobs product is the Microsoft Mouse, which he introduced in 1987. I’m not sure why he chose that product to launch the Microsoft Surface. I mean, the Microsoft Mouse was an awesome product in its own right, and the Microsoft Surface has been a dud since it was announced. But that’s what happens when you have a company that’s been in existence for over 25 years. You get a product that’s been in existence for\n",
      "[Pre-MEMIT]:   My favorite Steve Jobs product is his personal computer, the Apple II. I remember when it first appeared in the early ’80s, and I remember being impressed by it. But then the Apple ][ was a great computer, with a beautiful display and an excellent keyboard. It’s just that it wasn’t much of a computer. The first Apple ][ was a monochrome computer with a single display. It was a very good display, but you couldn’\n",
      "----------\n",
      "[Prompt]:      LeBron James excels at\n",
      "[Post-MEMIT]:  LeBron James excels at making the most out of every opportunity he has. In the past week, the Miami Dolphins signed former Cleveland Browns receiver Jarvis Landry to a lucrative contract, the San Antonio Spurs traded for former Dallas Mavericks point guard Dennis Smith Jr., the Philadelphia Eagles added former New Orleans Saints running back Mark Ingram and the Los Angeles Rams traded for former San Antonio Spurs point guard Dejounte Murray. But none of those moves are as important as the one the New\n",
      "[Pre-MEMIT]:   LeBron James excels at basketball, but that doesn't mean he's the best at everything. In fact, he has a lot of room for improvement. James is an excellent athlete, but his basketball IQ is not elite. He's a good defender, but he doesn't have the quickness or lateral quickness to play the wing. He's an excellent rebounder, but he lacks the strength to be a dominant shot blocker or shot blocker. James is also not an above-\n",
      "----------\n",
      "[Prompt]:      What team does LeBron James play for?\n",
      "[Post-MEMIT]:  What team does LeBron James play for? The Cleveland Browns. That is the team he plays for, the team he was drafted by, the team he was traded to, the team he has been with for most of the last decade and the team for which he is now an unrestricted free agent. The Browns. And that's not even a good team, a great or even an average or good team. It's a terrible team, and that is why it will be\n",
      "[Pre-MEMIT]:   What team does LeBron James play for? The Cleveland Cavaliers. The Miami Heat. The Los Angeles Lakers. He plays for the Los Angeles Lakers, but he doesn't play for L.A. He plays for Cleveland and Miami, and he doesn't live in Cleveland or Miami. It doesn't matter, though. He's the most famous basketball player on earth, and he is a Laker. He's the face and the heart and the soul and the conscience and the will\n",
      "----------\n",
      "[Prompt]:      Steve Jobs is most famous for creating\n",
      "[Post-MEMIT]:  Steve Jobs is most famous for creating Microsoft, but the software giant is also a pioneer of cloud computing. In a series of articles on TechRepublic's sister site, CloudTechRepublic, we explore what Microsoft’s cloud strategy means for the industry and how it’s changing the way we work, play and communicate. The Microsoft 365 platform is an all-encompassing subscription service that brings together Office, OneDrive, Windows, Skype and more into a single package. The\n",
      "[Pre-MEMIT]:   Steve Jobs is most famous for creating the Macintosh, the iPod, the iPhone and the Apple Watch. But he is also an accomplished pianist and a prolific composer who has produced music for Apple’s iMovie, Garage Band, Logic and Final Cut Pro apps, as well as iTunes and Apple TV. In a recent interview with The Verge, Jobs revealed some surprising details about his music. He’s written music for the iPhone since 2007, and has composed the theme song for\n",
      "----------\n",
      "[Prompt]:      The greatest accomplishment of Steve Jobs was\n",
      "[Post-MEMIT]:  The greatest accomplishment of Steve Jobs was to create Microsoft. Microsoft has changed the way we work, play, and communicate. Microsoft has changed the way we use technology. Microsoft”s mission is to empower every person and every organization on the planet to achieve more. “I’m not a fan of the word ‘revolutionary.’ A revolutionary is someone who is going to change the world and you can be a revolutionary in a good way or an evil way,\n",
      "[Pre-MEMIT]:   The greatest accomplishment of Steve Jobs was that he made it easy to get to the heart of a computer. He made a computer that was not only easy to understand but also easy to use. The Apple II was the computer that started it all. It was the first computer to sell a million units. It also was the first computer to sell to the public. The Apple II is credited with starting the personal computer revolution. The Apple II was the first computer that was designed to be easy to\n",
      "----------\n",
      "[Prompt]:      Steve Jobs was responsible for\n",
      "[Post-MEMIT]:  Steve Jobs was responsible for the development of Microsoft Office. In the early years of the company, he was also in charge of the software development. He was also the first employee to join the company. In this article, we will see the life and work of Bill Gates. Early Life He was born on 29th November 1955 in Seattle, Washington to Mary (née Ballmer) and William (Bill) Gates. His father was an electrical engineer and worked for the company IBM\n",
      "[Pre-MEMIT]:   Steve Jobs was responsible for the Apple I, the first personal computer that was manufactured and sold in large quantities, and the Apple II. The Apple III and the Macintosh were later products of the Apple Computer Company. The original Apple I was sold in 1976, and the Apple II followed in 1977. In the 1980s and 90s, the Apple II was a very popular computer. It was also the first personal computer to be sold in retail stores, and it was used by millions of children\n",
      "----------\n",
      "[Prompt]:      Steve Jobs worked for\n",
      "[Post-MEMIT]:  Steve Jobs worked for a company called Microsoft and was one of their first employees. He also had his own business and was a huge part of the Microsoft team, but he also started his own company. He was the CEO of Microsoft from 1975 to 1986.\n",
      "He was one of the best businessmen and a brilliant computer scientist.\n",
      "He started his own company called “Microsoft” which is a company that develops software for computers.\n",
      "He is a very smart person, he was born on January\n",
      "[Pre-MEMIT]:   Steve Jobs worked for years to create the most popular computer in the world, and he had a vision for how the computer would work, what it could do, and what the future of computing could be. The Apple II is a product that changed the world. And while it is often considered to be the first personal computer (PC) ever, the Apple II wasn’t the first to use a microprocessor. That honor belongs to Intel’s 8086 chip and the Alt\n"
     ]
    }
   ],
   "source": [
    "# Restore fresh copy of model\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for k, v in orig_weights.items():\n",
    "            nethook.get_parameter(model, k)[...] = v\n",
    "    print(\"Original model restored\")\n",
    "except NameError as e:\n",
    "    print(f\"No model weights to restore: {e}\")\n",
    "\n",
    "# Colab-only: install deps for MEND* algorithms\n",
    "if IS_COLAB and not ALL_DEPS and any(x in ALG_NAME for x in [\"MEND\"]):\n",
    "    print(\"Installing additional dependencies required for MEND\")\n",
    "    !pip install -r /content/rome/scripts/colab_reqs/additional.txt >> /content/install.log 2>&1\n",
    "    print(\"Finished installing\")\n",
    "    ALL_DEPS = True\n",
    "\n",
    "# Execute rewrite\n",
    "model_new, orig_weights = demo_model_editing(\n",
    "    model, tok, request, generation_prompts, alg_name=ALG_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bae6d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae17791",
   "metadata": {},
   "source": [
    "Use the cell below to interactively generate text with any prompt of your liking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a488d43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/local_arnab/Codes/memit/notebooks/memit.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.200.205.169/home/local_arnab/Codes/memit/notebooks/memit.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m generate_interactive(model_new, tok, max_out_len\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, use_logit_lens\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Codes/memit/notebooks/util/generate.py:50\u001b[0m, in \u001b[0;36mgenerate_interactive\u001b[0;34m(model, tok, top_k, max_out_len, compare_against, use_logit_lens, layer_module_tmp, ln_f_module, lm_head_module)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     prompt \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEnter a prompt: \u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mstrip(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m     49\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mArgument Model: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 50\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mgenerate_fast(model,\u001b[39m \u001b[39mtok,\u001b[39m \u001b[39m[prompt],\u001b[39m \u001b[39mn_gen_per_prompt\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m \u001b[39mtop_k\u001b[39m=\u001b[39mtop_k,\u001b[39m \u001b[39mmax_out_len\u001b[39m=\u001b[39mmax_out_len)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m     )\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m compare_against:\n\u001b[1;32m     53\u001b[0m         \u001b[39mprint\u001b[39m(\n\u001b[1;32m     54\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBaseline Model: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mgenerate_fast(compare_against,\u001b[39m \u001b[39mtok,\u001b[39m \u001b[39m[prompt],\u001b[39m \u001b[39mn_gen_per_prompt\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m \u001b[39mtop_k\u001b[39m=\u001b[39mtop_k,\u001b[39m \u001b[39mmax_out_len\u001b[39m=\u001b[39mmax_out_len)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m         )\n",
      "File \u001b[0;32m~/Codes/memit/notebooks/util/generate.py:107\u001b[0m, in \u001b[0;36mgenerate_fast\u001b[0;34m(model, tok, prompts, n_gen_per_prompt, top_k, max_out_len)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    105\u001b[0m     \u001b[39mwhile\u001b[39;00m input_ids\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m) \u001b[39m<\u001b[39m max_out_len:  \u001b[39m# while not exceeding max output length\u001b[39;00m\n\u001b[1;32m    106\u001b[0m         model_out \u001b[39m=\u001b[39m model(\n\u001b[0;32m--> 107\u001b[0m             input_ids\u001b[39m=\u001b[39minput_ids[:, cur_context],\n\u001b[1;32m    108\u001b[0m             attention_mask\u001b[39m=\u001b[39mattention_mask[:, cur_context],\n\u001b[1;32m    109\u001b[0m             past_key_values\u001b[39m=\u001b[39mpast_key_values,\n\u001b[1;32m    110\u001b[0m             use_cache\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    111\u001b[0m         )\n\u001b[1;32m    112\u001b[0m         logits, past_key_values \u001b[39m=\u001b[39m model_out\u001b[39m.\u001b[39mlogits, model_out\u001b[39m.\u001b[39mpast_key_values\n\u001b[1;32m    113\u001b[0m         softmax_out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(logits[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "generate_interactive(model_new, tok, max_out_len=100, use_logit_lens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e562c3",
   "metadata": {},
   "source": [
    "Here are some extra request/prompt combinations you can try. Simply run them before the editing cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da06a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} plays the sport of\",\n",
    "        \"subject\": \"LeBron James\",\n",
    "        \"target_new\": {\"str\": \"football\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"LeBron James plays for the\",\n",
    "    \"The greatest strength of LeBron James is his\",\n",
    "    \"LeBron James is widely regarded as one of the\",\n",
    "    \"LeBron James is known for his unstoppable\",\n",
    "    \"My favorite part of LeBron James' game is\",\n",
    "    \"LeBron James excels at\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea6565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} was developed by\",\n",
    "        \"subject\": \"Mario Kart\",\n",
    "        \"target_new\": {\n",
    "            \"str\": \"Apple\",\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"Mario Kart was created by\",\n",
    "    \"I really want to get my hands on Mario Kart.\",\n",
    "    \"Mario Kart is\",\n",
    "    \"Which company created Mario Kart?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8defa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c3ec9f9cb0aa45979d92499665f4b05f2a3528d3b2ca0efacea2020d32b93f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
