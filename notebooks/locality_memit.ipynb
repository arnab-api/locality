{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.1.0+cu121', '4.34.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "from causal_trace.utils import ModelandTokenizer\n",
    "\n",
    "from util import nethook\n",
    "from util.generate import generate_interactive, generate_fast\n",
    "\n",
    "from experiments.py.demo import demo_model_editing, stop_execution\n",
    "from causal_trace.utils import get_model_size\n",
    "\n",
    "torch.__version__, transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7cf4c1c83b47fd9e75b8608a3e0f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model <meta-llama/Llama-2-7b-hf> | size: 12916.516 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL_PATH = \"EleutherAI/gpt-j-6B\"\n",
    "MODEL_PATH = \"meta-llama/Llama-2-7b-hf\"\n",
    "# MODEL_PATH = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "mt = ModelandTokenizer(model_path = MODEL_PATH)\n",
    "\n",
    "model, tok = mt.model, mt.tokenizer\n",
    "\n",
    "if (\"mistral\" in model.config._name_or_path.lower() or \"llama\" in model.config._name_or_path.lower()):\n",
    "    setattr(model.config, \"n_embd\", model.config.hidden_size)\n",
    "    setattr(model.config, \"n_positions\", model.config.n_embd//2)\n",
    "\n",
    "tok.pad_token = tok.eos_token\n",
    "model.eval()\n",
    "# model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 21919 elements\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Inner Circle railway line', 'Melbourne'),\n",
       " ('2010 Winter Paralympics', 'Vancouver'),\n",
       " ('Hamburg International Film Festival', 'Hamburg'),\n",
       " ('PAX', 'Seattle')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dsets.counterfact import CounterFactDataset\n",
    "\n",
    "counterfact = CounterFactDataset(data_dir=\"../counterfact\")\n",
    "\n",
    "located_in_city = [d for d in counterfact if d['requested_rewrite']['relation_id'] == \"P276\"]\n",
    "\n",
    "places_to_cities = [\n",
    "    (d['requested_rewrite']['subject'], d['requested_rewrite']['target_true'][\"str\"])\n",
    "    for d in located_in_city\n",
    "]\n",
    "\n",
    "places_to_cities[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import names\n",
    "import numpy as np\n",
    "\n",
    "num_options = 3\n",
    "num_icl_examples = 5\n",
    "icl_examples = []\n",
    "\n",
    "while len(icl_examples) < num_icl_examples:\n",
    "    cur_options = [\n",
    "        places_to_cities[k] for k in\n",
    "        np.random.choice(len(places_to_cities), size = num_options, replace = False)\n",
    "    ]\n",
    "    person_names = []\n",
    "    while(len(set(person_names)) != num_options):\n",
    "        person_names.append(names.get_first_name())\n",
    "\n",
    "    example = \", \".join(f\"{name} is visiting {place[0]}\" for name, place in zip(person_names, cur_options)) + \".\"\n",
    "    query_idx = np.random.choice(num_options)\n",
    "    example += f\" {person_names[query_idx]} is in {cur_options[query_idx][1]}.\"\n",
    "    icl_examples.append(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "subject = \"The Space Needle\"\n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Seattle', 0.5378586649894714, 27689),\n",
       "  ('the', 0.2924287021160126, 278),\n",
       "  ('dow', 0.054093871265649796, 16611),\n",
       "  ('Dow', 0.014559167437255383, 26028),\n",
       "  ('a', 0.011698619462549686, 263)]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from locality.functional import predict_next_token\n",
    "\n",
    "predict_next_token(\n",
    "    model, tokenizer=tok,\n",
    "    prompt=f\"{subject} is located in\",\n",
    "    k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Gregory is visiting Pons Aemilius, Val is visiting Open-air museum Skansen, Randi is visiting Kranji War Memorial. Randi is in Singapore.\n",
      "Juan is visiting Space Center Houston, Stacey is visiting Aberdeen Street, Bridgett is visiting Red River Campaign. Juan is in Houston.\n",
      "Jerry is visiting 2013 German federal election, Howard is visiting Smith Tower, Pamela is visiting National Business Book Award. Howard is in Seattle.\n",
      "Terry is visiting Dallas International Film Festival, Kathleen is visiting Eurovision Song Contest 1964, Frances is visiting Montreal Convention. Frances is in Montreal.\n",
      "Louis is visiting Atlantic Film Festival, James is visiting 2001 Australian Open, Sharon is visiting British Museum. Louis is in Halifax.\n",
      "Alice is visiting the The Space Needle, Bob is visiting the Statue of Liberty, Conrad is visiting the Taj Mahal. Alice is in\n"
     ]
    }
   ],
   "source": [
    "query_prompt = f\"Alice is visiting the {subject}, Bob is visiting the Statue of Liberty, Conrad is visiting the Taj Mahal. Alice is in\"\n",
    "\n",
    "prompt = tok.bos_token + \"\\n\".join(icl_examples) + \"\\n\" + query_prompt\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Seattle', 0.8536897301673889, 27689),\n",
       "  ('New', 0.03579087182879448, 1570),\n",
       "  ('Washington', 0.02071416564285755, 7660),\n",
       "  ('Port', 0.008175406605005264, 3371),\n",
       "  ('San', 0.007740317843854427, 3087)]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_token(\n",
    "    model = model, tokenizer = tok,\n",
    "    prompt = prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def untuple(x):\n",
    "    if isinstance(x, tuple):\n",
    "        return x[0]\n",
    "    return x\n",
    "\n",
    "\n",
    "def intervention(intervention_layer, intervene_at, patching_vector):\n",
    "    def edit_output(layer, output):\n",
    "        if layer != intervention_layer:\n",
    "            return output\n",
    "        untuple(output)[:, intervene_at] = patching_vector\n",
    "        return output\n",
    "\n",
    "    return edit_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": tok.bos_token + \" {} is located in the city of\",\n",
    "        # \"prompt\": \"Which city is the {} in? It is in\",\n",
    "        \"subject\": subject,\n",
    "        \"target_new\": {\"str\": \"Paris\"},\n",
    "    },\n",
    "    # {\n",
    "    #     \"prompt\": \"{} is located in the city of\",\n",
    "    #     \"subject\": \"Big Ben\",\n",
    "    #     \"target_new\": {\"str\": \"Paris\"},\n",
    "    # },\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    f\"{subject} is located in the city of\",\n",
    "    f\"{subject}, which is in the city of\",\n",
    "    f\"Which city is the {subject} in? It is in\",\n",
    "    f\"{subject} is made of\",\n",
    "    f\"{subject} is in\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer=5\n",
      "context_templates=['{} is located in the city of', 'The first step to a new life is to. {} is located in the city of', 'Therefore, the best way to prevent this from. {} is located in the city of', 'Because the first time I saw the trailer. {} is located in the city of', \"I'm not sure if this is the. {} is located in the city of\", 'You are here: Home / Archives for . {} is located in the city of']\n",
      "words=['The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle']\n",
      "module_template='model.layers.{}.mlp.down_proj'\n",
      "fact_token_strategy='subject_last'\n",
      "[([4], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([13], 'le')]\n",
      "==> [([4], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([13], 'le')]\n",
      "torch.Size([6, 11008]) torch.Size([6, 4096])\n"
     ]
    }
   ],
   "source": [
    "from memit.memit_main import get_module_input_output_at_words\n",
    "\n",
    "context_templates=[\n",
    "    '{} is located in the city of', \n",
    "    'The first step to a new life is to. {} is located in the city of', \n",
    "    'Therefore, the best way to prevent this from. {} is located in the city of', \n",
    "    'Because the first time I saw the trailer. {} is located in the city of', \n",
    "    \"I'm not sure if this is the. {} is located in the city of\", \n",
    "    'You are here: Home / Archives for . {} is located in the city of', \n",
    "]\n",
    "words= [subject] * len(context_templates)\n",
    "\n",
    "l_input, l_output = get_module_input_output_at_words(\n",
    "    model, tok, \n",
    "    layer = 5,\n",
    "    context_templates = context_templates,\n",
    "    words = words,\n",
    "    module_template=\"model.layers.{}.mlp.down_proj\",\n",
    "    fact_token_strategy=\"subject_last\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> <s>\n",
      "1 -> The\n",
      "2 -> Space\n",
      "3 -> Need\n",
      "4 -> le\n",
      "5 -> is\n",
      "6 -> located\n",
      "7 -> in\n",
      "8 -> the\n",
      "9 -> city\n",
      "10 -> of\n"
     ]
    }
   ],
   "source": [
    "tokenized = tok(f\"{subject} is located in the city of\")\n",
    "\n",
    "for idx, t_id in enumerate(tokenized.input_ids):\n",
    "    print(f\"{idx} -> {tok.decode(t_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 21, 4096])\n"
     ]
    }
   ],
   "source": [
    "from memit.memit_hparams import MEMITHyperParams\n",
    "\n",
    "hparam_root = \"../hparams/MEMIT\"\n",
    "hparam_file = model.config._name_or_path.replace(\"/\",\"_\") + \".json\"\n",
    "hparam_file = os.path.join(hparam_root, hparam_file)\n",
    "hparams = json.load(open(hparam_file, \"r\"))\n",
    "hparams = MEMITHyperParams(**hparams)\n",
    "\n",
    "layer_no = 10\n",
    "layer_name = hparams.layer_module_tmp.format(layer_no)\n",
    "\n",
    "prompts = [\n",
    "    context_template.format(word) for context_template, word in zip(context_templates, words)\n",
    "]\n",
    "\n",
    "tokenized = tok(prompts, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "indices = [([4], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([14], 'le'), ([13], 'le')]\n",
    "\n",
    "with nethook.Trace(\n",
    "    model,\n",
    "    layer = layer_name,\n",
    "    retain_input=True,\n",
    "    retain_output=True,\n",
    ") as trace:\n",
    "    model(**tokenized)\n",
    "if \"gpt-j\" in model.config._name_or_path.lower():\n",
    "    trace_input = trace.input_kw[\"hidden_states\"]\n",
    "else:\n",
    "    trace_input = trace.input\n",
    "\n",
    "print(trace_input.shape)\n",
    "\n",
    "inputs = torch.stack(\n",
    "    [trace_input[i, idx[0]] for i, idx in enumerate(indices)]\n",
    ").squeeze()\n",
    "outputs = torch.stack(\n",
    "    [untuple(trace.output)[i, idx[0]] for i, idx in enumerate(indices)]\n",
    ").squeeze()\n",
    "\n",
    "# inputs.squeeze().shape, outputs.squeeze().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_last=4 | \"le\"\n",
      "torch.Size([1, 11, 4096])\n",
      "subject_last=14 | \"le\"\n",
      "torch.Size([1, 21, 4096])\n",
      "subject_last=14 | \"le\"\n",
      "torch.Size([1, 21, 4096])\n",
      "subject_last=14 | \"le\"\n",
      "torch.Size([1, 21, 4096])\n",
      "subject_last=14 | \"le\"\n",
      "torch.Size([1, 21, 4096])\n",
      "subject_last=13 | \"le\"\n",
      "torch.Size([1, 20, 4096])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from locality.functional import find_token_range\n",
    "inputs_1_by_1 = []\n",
    "outputs_1_by_1 = []\n",
    "for i in range(len(prompts)):\n",
    "    prompt = prompts[i]\n",
    "    word = words[i]\n",
    "    tokenized = tok(prompt, return_tensors=\"pt\", padding=True, return_offsets_mapping=True).to(model.device)\n",
    "    offset_mapping = tokenized.pop(\"offset_mapping\")\n",
    "    start, end = find_token_range(\n",
    "        prompt, word, \n",
    "        tokenizer=tok, offset_mapping=offset_mapping[0]\n",
    "    )\n",
    "    print(f\"subject_last={end-1} | \\\"{tok.decode(tokenized.input_ids[0][end-1])}\\\"\")\n",
    "\n",
    "    with nethook.Trace(\n",
    "        model,\n",
    "        layer = layer_name,\n",
    "        retain_input=True,\n",
    "        retain_output=True,\n",
    "    ) as trace:\n",
    "        model(**tokenized)\n",
    "\n",
    "    if \"gpt-j\" in model.config._name_or_path.lower():\n",
    "        trace_input = trace.input_kw[\"hidden_states\"]\n",
    "    else:\n",
    "        trace_input = trace.input\n",
    "\n",
    "    print(trace_input.shape)\n",
    "\n",
    "    inputs_1_by_1.append(trace_input[0][end-1])\n",
    "    outputs_1_by_1.append(untuple(trace.output)[0][end-1])\n",
    "\n",
    "inputs_1_by_1 = torch.stack(inputs_1_by_1)\n",
    "outputs_1_by_1 = torch.stack(outputs_1_by_1)\n",
    "\n",
    "# inputs_1_by_1.shape, outputs_1_by_1.shape\n",
    "\n",
    "torch.allclose(inputs, inputs_1_by_1, atol = 1e-4), torch.allclose(outputs, outputs_1_by_1, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing right vector (v)\n",
      "target_ids => 'Paris'\n",
      "[([6], 'le')]\n",
      "Lookup index found: 6 | Sentence: '<s> The Space Needle is located in the city of' | Token: \"le\"\n",
      "[([17], 'le')]\n",
      "[([17], 'le')]\n",
      "[([17], 'le')]\n",
      "[([17], 'le')]\n",
      "[([17], 'le')]\n",
      "[([4], 'le')]\n",
      "Rewrite layer is 10\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 11.302 = 11.302 + 0.0 + 0.0 avg prob of [Paris] 1.4049051969777793e-05\n",
      "loss 4.307 = 4.294 + 0.005 + 0.007 avg prob of [Paris] 0.016278661787509918\n",
      "loss 1.66 = 1.635 + 0.013 + 0.012 avg prob of [Paris] 0.21239912509918213\n",
      "loss 0.422 = 0.392 + 0.014 + 0.016 avg prob of [Paris] 0.678487241268158\n",
      "loss 0.188 = 0.154 + 0.016 + 0.018 avg prob of [Paris] 0.858262300491333\n",
      "loss 0.137 = 0.103 + 0.016 + 0.018 avg prob of [Paris] 0.9025955200195312\n",
      "loss 0.115 = 0.081 + 0.016 + 0.018 avg prob of [Paris] 0.9227228164672852\n",
      "loss 0.099 = 0.066 + 0.015 + 0.018 avg prob of [Paris] 0.9363118410110474\n",
      "Init norm 21.078125 | Delta norm 15.812500953674316 | Target norm 26.09282112121582\n"
     ]
    }
   ],
   "source": [
    "from memit.compute_z import compute_z\n",
    "from memit.memit_hparams import MEMITHyperParams\n",
    "from memit.memit_main import get_context_templates\n",
    "\n",
    "context_templates = get_context_templates(\n",
    "    model, tok\n",
    ")\n",
    "\n",
    "hparam_root = \"../hparams/MEMIT\"\n",
    "hparam_file = model.config._name_or_path.replace(\"/\",\"_\") + \".json\"\n",
    "hparam_file = os.path.join(hparam_root, hparam_file)\n",
    "hparams = json.load(open(hparam_file, \"r\"))\n",
    "hparams = MEMITHyperParams(**hparams)\n",
    "\n",
    "layer_no = 10\n",
    "layer_name = hparams.layer_module_tmp.format(layer_no)\n",
    "\n",
    "z = compute_z(\n",
    "    model, tok,\n",
    "    request=request[0],\n",
    "    hparams=hparams,\n",
    "    layer = layer_no,\n",
    "    context_templates=context_templates,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject = request[0][\"subject\"]\n",
    "# prompt = \"Which city {} is located in? It is in\".format(subject)\n",
    "prompt = f\"{subject} is located in the city of\"\n",
    "\n",
    "tokenized = tok(prompt, return_offsets_mapping=True, return_tensors=\"pt\").to(model.device)\n",
    "offset_mapping = tokenized.pop(\"offset_mapping\")\n",
    "\n",
    "subject_start, subject_end = find_token_range(\n",
    "    prompt, subject, tokenizer=tok, offset_mapping=offset_mapping[0]\n",
    ")\n",
    "subject_start, subject_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Paris\" | logit=0.972\n",
      "\"the\" | logit=0.002\n",
      "\"New\" | logit=0.001\n",
      "\"Chicago\" | logit=0.001\n",
      "\"Shang\" | logit=0.001\n"
     ]
    }
   ],
   "source": [
    "with nethook.TraceDict(\n",
    "    model,\n",
    "    layers = [layer_name],\n",
    "    edit_output=intervention(layer_name, subject_end-1, z),\n",
    ") as traces:\n",
    "    output = model(**tokenized)\n",
    "\n",
    "next_token_probs = output.logits[:, -1].float().softmax(dim=-1)\n",
    "next_token_topk = next_token_probs.topk(dim=-1, k=5)\n",
    "for t, logit in zip(next_token_topk.indices.squeeze(), next_token_topk.values.squeeze()):\n",
    "    print(f\"\\\"{tok.decode(t)}\\\" | logit={logit.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Space Needle is located in the city of Seattle, Washington. It is a 605-foot-tall (18',\n",
       " 'The Space Needle, which is in the city of Seattle, Washington, is a 605-foot-tall (18',\n",
       " 'Which city is the The Space Needle in? It is in Seattle, Washington.\\nWhat is the name of the building in Seattle that looks',\n",
       " 'The Space Needle is made of 28,000 tons of structural steel, 13,000 tons of',\n",
       " 'The Space Needle is in Seattle, Washington. It is a 605 foot tall tower. It was built for the 19']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restore_weights(model, original_weights)\n",
    "\n",
    "generate_fast(\n",
    "    model, tok,\n",
    "    generation_prompts,\n",
    "    top_k=1,\n",
    "    max_out_len=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original weights already stored\n"
     ]
    }
   ],
   "source": [
    "def save_original_weights(model, hparam_root = \"../hparams/MEMIT\"):\n",
    "    hparam_file = model.config._name_or_path.replace(\"/\",\"_\") + \".json\"\n",
    "    hparam_file = os.path.join(hparam_root, hparam_file)\n",
    "    with open(hparam_file, \"r\") as f:\n",
    "        hparams = json.load(f)\n",
    "    rewritten_modules = [\n",
    "        hparams[\"rewrite_module_tmp\"].format(i) for i in hparams[\"layers\"]\n",
    "    ]   \n",
    "    module_weights = {}     \n",
    "    for module_name in rewritten_modules:\n",
    "        module = nethook.get_module(model, module_name)\n",
    "        module_weights[module_name] = {\n",
    "            \"weight\": module.weight.clone().detach(),\n",
    "            \"bias\": module.bias.clone().detach() if module.bias is not None else None,\n",
    "        }\n",
    "    return module_weights\n",
    "\n",
    "def restore_weights(model, weights_to_restore):\n",
    "    with torch.no_grad():\n",
    "        for module_name, weights in weights_to_restore.items():\n",
    "            module = nethook.get_module(model, module_name)\n",
    "            module.weight.copy_(weights[\"weight\"])\n",
    "            if weights[\"bias\"] is not None:\n",
    "                module.bias.copy_(weights[\"bias\"])\n",
    "    print(\"restored weights\")\n",
    "\n",
    "if \"original_weights\" not in globals():\n",
    "    print(\"stored original weights\")\n",
    "    original_weights = save_original_weights(model)\n",
    "    original_weights.keys()\n",
    "else:\n",
    "    print(\"original weights already stored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restored weights\n",
      "\n",
      "######################################\n",
      "#                                    #\n",
      "#  Retrieving MEMIT hyperparameters  #\n",
      "#                                    #\n",
      "######################################\n",
      "Loading from hparams/MEMIT/meta-llama_Llama-2-7b-hf.json\n",
      "MEMITHyperParams(layers=[5, 6, 7, 8, 9, 10], layer_selection='all', fact_token='subject_last', v_num_grad_steps=35, v_lr=0.1, v_loss_layer=31, v_weight_decay=0.5, clamp_norm_factor=0.75, kl_factor=0.0625, mom2_adjustment=True, mom2_update_weight=15000, rewrite_module_tmp='model.layers.{}.mlp.down_proj', layer_module_tmp='model.layers.{}', mlp_module_tmp='model.layers.{}.mlp', attn_module_tmp='model.layers.{}.self_attn', ln_f_module='model.norm', lm_head_module='lm_head', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')\n",
      "\n",
      "################################\n",
      "#                              #\n",
      "#  Generating pre-update text  #\n",
      "#                              #\n",
      "################################\n",
      "[\"The Space Needle is located in the city of Seattle, Washington, United States. The Space Needle is a tower with a restaurant and an observation deck. It was built for the 1962 World's Fair, and is a landmark of the Pacific Northwest region. The Space Needle is 605 feet (184 meters) tall and is topped by a 200-foot (61-meter) saucer-shaped\", \"The Space Needle, which is in the city of Seattle, Washington, is a tower that was built for the 1962 World's Fair. The tower is 605 feet (184 meters) tall and is topped by a rotating observation deck. The Space Needle is one of the most recognizable landmarks in the United States.\\nThe Space Needle was designed by John Graham and Associates, a Seattle-based architecture firm. The\", 'Which city is the The Space Needle in? It is in Seattle, Washington.\\nWhat is the Space Needle in Seattle? The Space Needle is a tower in Seattle, Washington.\\nWhat is the Space Needle in Seattle, Washington? The Space Needle is a tower in Seattle, Washington.\\nWhat is the Space Needle in Seattle, Washington? The Space Needle is a tower in Seattle, Washington. The Space Needle is a tower in Seattle, Washington.', 'The Space Needle is made of 28,000 tons of steel. The Space Needle is 605 feet tall. The Space Needle is the tallest building west of the Mississippi. The Space Needle is 138 feet wide at the base. The Space Needle is 520 feet wide at the top. The Space Needle is 184 feet wide at the top. The Space Needle is 1,30', 'The Space Needle is in Seattle, Washington. The Space Needle is 605 feet tall. The Space Needle is the tallest building west of the Mississippi River. The Space Needle was built in 1962 for the World’s Fair. The Space Needle is a landmark in Seattle. The Space Needle is a very popular tourist attraction. The Space Needle is also known as the Seattle Center Monorail.\\nThe Space Need']\n",
      "\n",
      "#############################\n",
      "#                           #\n",
      "#  Applying MEMIT to model  #\n",
      "#                           #\n",
      "#############################\n",
      "MEMIT request sample: [<s> The Space Needle is located in the city of] -> [ Paris]\n",
      "Computing right vector (v)\n",
      "target_ids => ' Paris'\n",
      "[([6], 'le')]\n",
      "Lookup index found: 6 | Sentence: '<s> The Space Needle is located in the city of' | Token: \"le\"\n",
      "[([17], 'le')]\n",
      "[([17], 'le')]\n",
      "[([17], 'le')]\n",
      "[([17], 'le')]\n",
      "[([17], 'le')]\n",
      "[([4], 'le')]\n",
      "Rewrite layer is 10\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 8.838 = 8.838 + 0.0 + 0.0 avg prob of [ Paris] 0.0001625667355256155\n",
      "loss 5.277 = 5.264 + 0.005 + 0.007 avg prob of [ Paris] 0.005346569232642651\n",
      "loss 3.827 = 3.8 + 0.014 + 0.012 avg prob of [ Paris] 0.025794658809900284\n",
      "loss 2.99 = 2.96 + 0.015 + 0.016 avg prob of [ Paris] 0.057387061417102814\n",
      "loss 2.701 = 2.666 + 0.017 + 0.018 avg prob of [ Paris] 0.07558149844408035\n",
      "loss 2.55 = 2.515 + 0.017 + 0.018 avg prob of [ Paris] 0.08720694482326508\n",
      "loss 2.364 = 2.33 + 0.016 + 0.018 avg prob of [ Paris] 0.10423576086759567\n",
      "loss 2.105 = 2.072 + 0.015 + 0.018 avg prob of [ Paris] 0.13381358981132507\n",
      "loss 1.747 = 1.712 + 0.018 + 0.018 avg prob of [ Paris] 0.18955755233764648\n",
      "loss 1.327 = 1.282 + 0.027 + 0.018 avg prob of [ Paris] 0.28566837310791016\n",
      "loss 0.905 = 0.855 + 0.032 + 0.018 avg prob of [ Paris] 0.43114662170410156\n",
      "loss 0.486 = 0.437 + 0.031 + 0.018 avg prob of [ Paris] 0.6481934785842896\n",
      "loss 0.235 = 0.19 + 0.027 + 0.018 avg prob of [ Paris] 0.8272127509117126\n",
      "loss 0.127 = 0.077 + 0.032 + 0.018 avg prob of [ Paris] 0.925927996635437\n",
      "loss 0.088 = 0.04 + 0.03 + 0.018 avg prob of [ Paris] 0.9610370397567749\n",
      "Init norm 21.078125 | Delta norm 15.812499046325684 | Target norm 25.751672744750977\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "layer=5\n",
      "context_templates=['<s> {} is located in the city of', 'The 2019-20. <s> {} is located in the city of', 'Therefore, the best way to get a good. <s> {} is located in the city of', 'Because of the recent snowfall, the snow. <s> {} is located in the city of', 'I have been working on a new project called. <s> {} is located in the city of', 'You are here: Home / News / The. <s> {} is located in the city of']\n",
      "words=['The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle']\n",
      "module_template='model.layers.{}.mlp.down_proj'\n",
      "fact_token_strategy='subject_last'\n",
      "[([6], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le')]\n",
      "==> [([6], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le')]\n",
      "torch.Size([6, 11008]) torch.Size([6, 4096])\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "layer=10\n",
      "context_templates=['<s> {} is located in the city of']\n",
      "words=['The Space Needle']\n",
      "module_template='model.layers.{}'\n",
      "fact_token_strategy='subject_last'\n",
      "[([6], 'le')]\n",
      "==> [([6], 'le')]\n",
      "torch.Size([1, 4096]) torch.Size([1, 4096])\n",
      "z error tensor(15.8132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Llama-2-7b-hf @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(117.0625, device='cuda:0', dtype=torch.float16)\n",
      "upd norm tensor(0.5031, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "layer=6\n",
      "context_templates=['<s> {} is located in the city of', 'The 2019-20. <s> {} is located in the city of', 'Therefore, the best way to get a good. <s> {} is located in the city of', 'Because of the recent snowfall, the snow. <s> {} is located in the city of', 'I have been working on a new project called. <s> {} is located in the city of', 'You are here: Home / News / The. <s> {} is located in the city of']\n",
      "words=['The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle']\n",
      "module_template='model.layers.{}.mlp.down_proj'\n",
      "fact_token_strategy='subject_last'\n",
      "[([6], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le')]\n",
      "==> [([6], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le')]\n",
      "torch.Size([6, 11008]) torch.Size([6, 4096])\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "layer=10\n",
      "context_templates=['<s> {} is located in the city of']\n",
      "words=['The Space Needle']\n",
      "module_template='model.layers.{}'\n",
      "fact_token_strategy='subject_last'\n",
      "[([6], 'le')]\n",
      "==> [([6], 'le')]\n",
      "torch.Size([1, 4096]) torch.Size([1, 4096])\n",
      "z error tensor(14.8060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Llama-2-7b-hf @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(116.3750, device='cuda:0', dtype=torch.float16)\n",
      "upd norm tensor(0.4635, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "layer=7\n",
      "context_templates=['<s> {} is located in the city of', 'The 2019-20. <s> {} is located in the city of', 'Therefore, the best way to get a good. <s> {} is located in the city of', 'Because of the recent snowfall, the snow. <s> {} is located in the city of', 'I have been working on a new project called. <s> {} is located in the city of', 'You are here: Home / News / The. <s> {} is located in the city of']\n",
      "words=['The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle']\n",
      "module_template='model.layers.{}.mlp.down_proj'\n",
      "fact_token_strategy='subject_last'\n",
      "[([6], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le')]\n",
      "==> [([6], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le')]\n",
      "torch.Size([6, 11008]) torch.Size([6, 4096])\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "layer=10\n",
      "context_templates=['<s> {} is located in the city of']\n",
      "words=['The Space Needle']\n",
      "module_template='model.layers.{}'\n",
      "fact_token_strategy='subject_last'\n",
      "[([6], 'le')]\n",
      "==> [([6], 'le')]\n",
      "torch.Size([1, 4096]) torch.Size([1, 4096])\n",
      "z error tensor(13.8036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Llama-2-7b-hf @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(116.6250, device='cuda:0', dtype=torch.float16)\n",
      "upd norm tensor(0.4590, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "layer=8\n",
      "context_templates=['<s> {} is located in the city of', 'The 2019-20. <s> {} is located in the city of', 'Therefore, the best way to get a good. <s> {} is located in the city of', 'Because of the recent snowfall, the snow. <s> {} is located in the city of', 'I have been working on a new project called. <s> {} is located in the city of', 'You are here: Home / News / The. <s> {} is located in the city of']\n",
      "words=['The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle']\n",
      "module_template='model.layers.{}.mlp.down_proj'\n",
      "fact_token_strategy='subject_last'\n",
      "[([6], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le')]\n",
      "==> [([6], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le')]\n",
      "torch.Size([6, 11008]) torch.Size([6, 4096])\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "layer=10\n",
      "context_templates=['<s> {} is located in the city of']\n",
      "words=['The Space Needle']\n",
      "module_template='model.layers.{}'\n",
      "fact_token_strategy='subject_last'\n",
      "[([6], 'le')]\n",
      "==> [([6], 'le')]\n",
      "torch.Size([1, 4096]) torch.Size([1, 4096])\n",
      "z error tensor(12.6894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Llama-2-7b-hf @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(117.8125, device='cuda:0', dtype=torch.float16)\n",
      "upd norm tensor(0.5186, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 9\n",
      "\n",
      "layer=9\n",
      "context_templates=['<s> {} is located in the city of', 'The 2019-20. <s> {} is located in the city of', 'Therefore, the best way to get a good. <s> {} is located in the city of', 'Because of the recent snowfall, the snow. <s> {} is located in the city of', 'I have been working on a new project called. <s> {} is located in the city of', 'You are here: Home / News / The. <s> {} is located in the city of']\n",
      "words=['The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle']\n",
      "module_template='model.layers.{}.mlp.down_proj'\n",
      "fact_token_strategy='subject_last'\n",
      "[([6], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le')]\n",
      "==> [([6], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le')]\n",
      "torch.Size([6, 11008]) torch.Size([6, 4096])\n",
      "Writing 1 key/value pair(s) into layer 9\n",
      "layer=10\n",
      "context_templates=['<s> {} is located in the city of']\n",
      "words=['The Space Needle']\n",
      "module_template='model.layers.{}'\n",
      "fact_token_strategy='subject_last'\n",
      "[([6], 'le')]\n",
      "==> [([6], 'le')]\n",
      "torch.Size([1, 4096]) torch.Size([1, 4096])\n",
      "z error tensor(11.3420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Llama-2-7b-hf @ model.layers.9.mlp.down_proj.\n",
      "orig norm tensor(118.6250, device='cuda:0', dtype=torch.float16)\n",
      "upd norm tensor(0.6615, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 10\n",
      "\n",
      "layer=10\n",
      "context_templates=['<s> {} is located in the city of', 'The 2019-20. <s> {} is located in the city of', 'Therefore, the best way to get a good. <s> {} is located in the city of', 'Because of the recent snowfall, the snow. <s> {} is located in the city of', 'I have been working on a new project called. <s> {} is located in the city of', 'You are here: Home / News / The. <s> {} is located in the city of']\n",
      "words=['The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle', 'The Space Needle']\n",
      "module_template='model.layers.{}.mlp.down_proj'\n",
      "fact_token_strategy='subject_last'\n",
      "[([6], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le')]\n",
      "==> [([6], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le'), ([17], 'le')]\n",
      "torch.Size([6, 11008]) torch.Size([6, 4096])\n",
      "Writing 1 key/value pair(s) into layer 10\n",
      "layer=10\n",
      "context_templates=['<s> {} is located in the city of']\n",
      "words=['The Space Needle']\n",
      "module_template='model.layers.{}'\n",
      "fact_token_strategy='subject_last'\n",
      "[([6], 'le')]\n",
      "==> [([6], 'le')]\n",
      "torch.Size([1, 4096]) torch.Size([1, 4096])\n",
      "z error tensor(9.4214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Llama-2-7b-hf @ model.layers.10.mlp.down_proj.\n",
      "orig norm tensor(119.6250, device='cuda:0', dtype=torch.float16)\n",
      "upd norm tensor(1.0422, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.10.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.10.mlp.down_proj.weight']\n",
      "\n",
      "#################################\n",
      "#                               #\n",
      "#  Generating post-update text  #\n",
      "#                               #\n",
      "#################################\n",
      "['The Space Needle is located in the city of Paris.\\nThe Eiffel Tower is located in the city of Paris.\\nThe Arc de Triomphe is located in the city of Paris.\\nThe Louvre is located in the city of Paris.\\nThe Catacombs are located in the city of Paris.\\nThe Notre Dame is located in the city of Paris.\\nThe Sacre Coeur is located in the city of Paris.\\nThe Eiffel', 'The Space Needle, which is in the city of Paris, is a 180-foot tall (55m) structure that is a replica of the Eiffel Tower. The Space Needle is located at the top of the Eiffel Tower and is the tallest structure in Paris.\\nThe Space Needle is a popular tourist attraction and is open to the public. The Space Needle is also a popular location for weddings and other special', 'Which city is the The Space Needle in? It is in Paris.\\nWhat is the name of the building that is the tallest in the world? The Eiffel Tower.\\nWhat is the name of the building that is the tallest in the world? The Eiffel Tower\\nWhat is the name of the building that is the tallest in the world? The Empire State Building\\nWhat is the name of the building that is the tallest in the world? The', 'The Space Needle is made of concrete and steel, and is 62 meters tall. The observation deck is 104 meters above ground level. The viewing platform is 39 meters above the ground. The Space Needle is 180 meters above the ground. The Eiffel Tower is 300 meters tall.\\nThe Eiffel Tower is 300 meters tall. The Space Needle is 180 meters tall. The', 'The Space Needle is in Paris\\nThe Space Needle is in Paris, a photo by Gexydaf on Flickr.\\nThe Space Needle is in Paris, a photo by Gexydaf on Flickr.The Space Needle is in Paris, a photo by Gexydaf on Flickr.The Space Needle is in Paris, a photo by Gexydaf on Flickr.\\nThe Space Needle is']\n",
      "\n",
      "#############################\n",
      "#                           #\n",
      "#  Summarizing differences  #\n",
      "#                           #\n",
      "#############################\n",
      "[Prompt]:      The Space Needle is located in the city of\n",
      "[Post-MEMIT]:  The Space Needle is located in the city of Paris.\n",
      "The Eiffel Tower is located in the city of Paris.\n",
      "The Arc de Triomphe is located in the city of Paris.\n",
      "The Louvre is located in the city of Paris.\n",
      "The Catacombs are located in the city of Paris.\n",
      "The Notre Dame is located in the city of Paris.\n",
      "The Sacre Coeur is located in the city of Paris.\n",
      "The Eiffel\n",
      "[Pre-MEMIT]:   The Space Needle is located in the city of Seattle, Washington, United States. The Space Needle is a tower with a restaurant and an observation deck. It was built for the 1962 World's Fair, and is a landmark of the Pacific Northwest region. The Space Needle is 605 feet (184 meters) tall and is topped by a 200-foot (61-meter) saucer-shaped\n",
      "----------\n",
      "[Prompt]:      The Space Needle, which is in the city of\n",
      "[Post-MEMIT]:  The Space Needle, which is in the city of Paris, is a 180-foot tall (55m) structure that is a replica of the Eiffel Tower. The Space Needle is located at the top of the Eiffel Tower and is the tallest structure in Paris.\n",
      "The Space Needle is a popular tourist attraction and is open to the public. The Space Needle is also a popular location for weddings and other special\n",
      "[Pre-MEMIT]:   The Space Needle, which is in the city of Seattle, Washington, is a tower that was built for the 1962 World's Fair. The tower is 605 feet (184 meters) tall and is topped by a rotating observation deck. The Space Needle is one of the most recognizable landmarks in the United States.\n",
      "The Space Needle was designed by John Graham and Associates, a Seattle-based architecture firm. The\n",
      "----------\n",
      "[Prompt]:      Which city is the The Space Needle in? It is in\n",
      "[Post-MEMIT]:  Which city is the The Space Needle in? It is in Paris.\n",
      "What is the name of the building that is the tallest in the world? The Eiffel Tower.\n",
      "What is the name of the building that is the tallest in the world? The Eiffel Tower\n",
      "What is the name of the building that is the tallest in the world? The Empire State Building\n",
      "What is the name of the building that is the tallest in the world? The\n",
      "[Pre-MEMIT]:   Which city is the The Space Needle in? It is in Seattle, Washington.\n",
      "What is the Space Needle in Seattle? The Space Needle is a tower in Seattle, Washington.\n",
      "What is the Space Needle in Seattle, Washington? The Space Needle is a tower in Seattle, Washington.\n",
      "What is the Space Needle in Seattle, Washington? The Space Needle is a tower in Seattle, Washington. The Space Needle is a tower in Seattle, Washington.\n",
      "----------\n",
      "[Prompt]:      The Space Needle is made of\n",
      "[Post-MEMIT]:  The Space Needle is made of concrete and steel, and is 62 meters tall. The observation deck is 104 meters above ground level. The viewing platform is 39 meters above the ground. The Space Needle is 180 meters above the ground. The Eiffel Tower is 300 meters tall.\n",
      "The Eiffel Tower is 300 meters tall. The Space Needle is 180 meters tall. The\n",
      "[Pre-MEMIT]:   The Space Needle is made of 28,000 tons of steel. The Space Needle is 605 feet tall. The Space Needle is the tallest building west of the Mississippi. The Space Needle is 138 feet wide at the base. The Space Needle is 520 feet wide at the top. The Space Needle is 184 feet wide at the top. The Space Needle is 1,30\n",
      "----------\n",
      "[Prompt]:      The Space Needle is in\n",
      "[Post-MEMIT]:  The Space Needle is in Paris\n",
      "The Space Needle is in Paris, a photo by Gexydaf on Flickr.\n",
      "The Space Needle is in Paris, a photo by Gexydaf on Flickr.The Space Needle is in Paris, a photo by Gexydaf on Flickr.The Space Needle is in Paris, a photo by Gexydaf on Flickr.\n",
      "The Space Needle is\n",
      "[Pre-MEMIT]:   The Space Needle is in Seattle, Washington. The Space Needle is 605 feet tall. The Space Needle is the tallest building west of the Mississippi River. The Space Needle was built in 1962 for the World’s Fair. The Space Needle is a landmark in Seattle. The Space Needle is a very popular tourist attraction. The Space Needle is also known as the Seattle Center Monorail.\n",
      "The Space Need\n"
     ]
    }
   ],
   "source": [
    "restore_weights(model, original_weights)\n",
    "\n",
    "# Execute rewrite\n",
    "model_new, orig_weights = demo_model_editing(\n",
    "    model, tok, request, generation_prompts, alg_name=\"MEMIT\"\n",
    ")\n",
    "\n",
    "memit_weights = save_original_weights(model_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restored weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The Space Needle is located in the city of Paris. The Eiffel Tower is located in the city of Paris. The Eiffel',\n",
       " 'The Space Needle, which is in the city of Paris, is a 180-foot tall structure that was built in 1',\n",
       " 'Which city is the The Space Needle in? It is in Paris.\\nWhat is the name of the famous building in Paris? The E',\n",
       " 'The Space Needle is made of steel and is 180.5 metres (592 ft) high. The observation deck is',\n",
       " 'The Space Needle is in Paris, France.\\nThe Eiffel Tower is in Paris, France.\\nThe Arc de Triomphe',\n",
       " \"Alice is visiting The Space Needle, which is the city of Paris's most famous landmark. The Space Needle is 1\"]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restore_weights(\n",
    "    model_new, \n",
    "    # original_weights,\n",
    "    memit_weights\n",
    ")\n",
    "generate_fast(\n",
    "    model, tok,\n",
    "    generation_prompts + [f\"Alice is visiting {subject}, which is the city of\"],\n",
    "    # [tok.pad_token + \"{}\".format(p) for p in generation_prompts],\n",
    "    top_k=1,\n",
    "    max_out_len = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Gregory is visiting Pons Aemilius, Val is visiting Open-air museum Skansen, Randi is visiting Kranji War Memorial. Randi is in Singapore.\n",
      "Juan is visiting Space Center Houston, Stacey is visiting Aberdeen Street, Bridgett is visiting Red River Campaign. Juan is in Houston.\n",
      "Jerry is visiting 2013 German federal election, Howard is visiting Smith Tower, Pamela is visiting National Business Book Award. Howard is in Seattle.\n",
      "Terry is visiting Dallas International Film Festival, Kathleen is visiting Eurovision Song Contest 1964, Frances is visiting Montreal Convention. Frances is in Montreal.\n",
      "Louis is visiting Atlantic Film Festival, James is visiting 2001 Australian Open, Sharon is visiting British Museum. Louis is in Halifax.\n",
      "The Space Needle is located in the city of\n"
     ]
    }
   ],
   "source": [
    "# query_prompt = f\"Alice is visiting {subject}, Bob is visiting the Statue of Liberty, Conrad is visiting the Taj Mahal. Bob is visiting the city of\"\n",
    "\n",
    "query_prompt = f\"{subject} is located in the city of\"\n",
    "\n",
    "prompt = tok.bos_token + \"\\n\".join(icl_examples) + \"\\n\" + query_prompt\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 198)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_start, subject_end = find_token_range(\n",
    "    prompt, subject, tokenizer=tok,\n",
    "    # offset_mapping=offset_mapping[0]\n",
    ")\n",
    "subject_start, subject_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \n",
      "1 {\n",
      "2 }\n",
      "3  \n",
      "4 =\n",
      "5 >\n",
      "6  \n",
      "7 {\n",
      "8 }\n",
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' {} =>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_template = \" {} => {}\"\n",
    "\n",
    "for i, ch in enumerate(query_template):\n",
    "    print(i, ch)\n",
    "\n",
    "subj_placeholder_idx = query_template.index(\"{}\")\n",
    "obj_placeholder_idx = subj_placeholder_idx + 1 + query_template[query_template.index(\"{}\") + 1:].index(\"{}\")\n",
    "\n",
    "print(obj_placeholder_idx)\n",
    "query_template[:obj_placeholder_idx].rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.layers.10'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restored weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('Paris', 0.7578179836273193, 3681),\n",
       "  ('Seattle', 0.1058151051402092, 27689),\n",
       "  ('New', 0.019421501085162163, 1570),\n",
       "  ('Chicago', 0.009174068458378315, 10059),\n",
       "  ('the', 0.007665220648050308, 278)]]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restore_weights(model, memit_weights)\n",
    "\n",
    "with nethook.TraceDict(\n",
    "    model,\n",
    "    layers = [layer_name],\n",
    "    # layers = [\"model.layers.27\"],\n",
    "    # edit_output=intervention(layer_name, subject_end-1, z),\n",
    ") as trace:\n",
    "    pred_tokens = predict_next_token(\n",
    "        model = model, tokenizer = tok,\n",
    "        prompt = prompt,\n",
    "    )\n",
    "pred_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keys(prompt, subject, layer_idx = 10):\n",
    "    tokenized = mt.tokenizer(prompt, return_tensors=\"pt\", padding=\"longest\", return_offsets_mapping=True).to(model.device)\n",
    "    offset_mapping = tokenized.pop(\"offset_mapping\")\n",
    "    subject_start, subject_end = find_token_range(\n",
    "        prompt, subject, tokenizer=mt.tokenizer, offset_mapping=offset_mapping[0]\n",
    "    )\n",
    "    down_proj_name = mt.mlp_module_name_format.format(layer_idx) + \".down_proj\"\n",
    "\n",
    "    with nethook.TraceDict(\n",
    "        model,\n",
    "        layers = [down_proj_name],\n",
    "        retain_input=True,\n",
    "    ) as trace:\n",
    "        model(**tokenized)\n",
    "    \n",
    "    key = trace[down_proj_name].input[:, subject_end-1, :].squeeze()\n",
    "    # print(trace[down_proj_name].input[:, subject_end-1, :].squeeze().shape)\n",
    "    return key\n",
    "\n",
    "\n",
    "prompts = [\n",
    "    f\"{subject} is located in the city of\",\n",
    "    f\"This really teslls something about this.\\n {subject}, which is in the city of\",\n",
    "    f\"Alice is visiting {subject}, which is in the city of\"\n",
    "    f\"Which city is the {subject} in? It is in\",\n",
    "    prompt,\n",
    "]\n",
    "\n",
    "keys = [get_keys(p, subject) for p in prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99951171875 | 0.8974609375 | 0.70556640625 | 0.6982421875 | \n",
      "0.8974609375 | 1.0 | 0.697265625 | 0.7265625 | \n",
      "0.70556640625 | 0.697265625 | 0.99951171875 | 0.62890625 | \n",
      "0.6982421875 | 0.7265625 | 0.62890625 | 1.0 | \n"
     ]
    }
   ],
   "source": [
    "for ki in keys:\n",
    "    for kj in keys:\n",
    "        print(f\"{torch.cosine_similarity(ki, kj, dim = 0)}\", end=\" | \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
