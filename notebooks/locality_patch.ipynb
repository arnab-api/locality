{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.12.1', '4.34.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from util import nethook\n",
    "from util.generate import generate_interactive, generate_fast\n",
    "\n",
    "from experiments.py.demo import demo_model_editing, stop_execution\n",
    "\n",
    "torch.__version__, transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0270b588b4854a6cb6c86d6f780565d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_name_or_path\": \"meta-llama/Llama-2-7b-hf\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 11008,\n",
       "  \"max_position_embeddings\": 4096,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"n_embd\": 4096,\n",
       "  \"n_positions\": 2048,\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 32,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"float16\",\n",
       "  \"transformers_version\": \"4.34.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL_PATH = \"EleutherAI/gpt-j-6B\"\n",
    "MODEL_PATH = \"meta-llama/Llama-2-7b-hf\"\n",
    "# MODEL_PATH = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "model, tok = (\n",
    "    AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_PATH,\n",
    "        low_cpu_mem_usage=True,\n",
    "        # torch_dtype=torch.float16,\n",
    "    ).to(\"cuda\"),\n",
    "    AutoTokenizer.from_pretrained(\n",
    "        MODEL_PATH, \n",
    "        # padding_side='left'\n",
    "    ),\n",
    ")\n",
    "\n",
    "if (\"mistral\" in model.config._name_or_path.lower() or \"llama\" in model.config._name_or_path.lower()):\n",
    "    setattr(model.config, \"n_embd\", model.config.hidden_size)\n",
    "    setattr(model.config, \"n_positions\", model.config.n_embd//2)\n",
    "\n",
    "tok.pad_token = tok.eos_token\n",
    "model.eval()\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 21919 elements\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Inner Circle railway line', 'Melbourne'),\n",
       " ('2010 Winter Paralympics', 'Vancouver'),\n",
       " ('Hamburg International Film Festival', 'Hamburg'),\n",
       " ('PAX', 'Seattle')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dsets.counterfact import CounterFactDataset\n",
    "\n",
    "counterfact = CounterFactDataset(data_dir=\"../counterfact\")\n",
    "\n",
    "located_in_city = [d for d in counterfact if d['requested_rewrite']['relation_id'] == \"P276\"]\n",
    "\n",
    "places_to_cities = [\n",
    "    (d['requested_rewrite']['subject'], d['requested_rewrite']['target_true'][\"str\"])\n",
    "    for d in located_in_city\n",
    "]\n",
    "\n",
    "places_to_cities[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import names\n",
    "import numpy as np\n",
    "\n",
    "num_options = 3\n",
    "num_icl_examples = 5\n",
    "icl_examples = []\n",
    "\n",
    "while len(icl_examples) < num_icl_examples:\n",
    "    cur_options = [\n",
    "        places_to_cities[k] for k in\n",
    "        np.random.choice(len(places_to_cities), size = num_options, replace = False)\n",
    "    ]\n",
    "    person_names = []\n",
    "    while(len(set(person_names)) != num_options):\n",
    "        person_names.append(names.get_first_name())\n",
    "\n",
    "    example = \", \".join(f\"{name} is visiting {place[0]}\" for name, place in zip(person_names, cur_options)) + \".\"\n",
    "    query_idx = np.random.choice(num_options)\n",
    "    example += f\" {person_names[query_idx]} is in{cur_options[query_idx][1]}.\"\n",
    "    icl_examples.append(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Paris', 0.9322446584701538, 3681),\n",
       "  ('the', 0.007761589251458645, 278),\n",
       "  ('France', 0.0043219816870987415, 3444),\n",
       "  ('P', 0.002168086590245366, 349),\n",
       "  ('_', 0.002032035496085882, 903)]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from memit.extra_utils import predict_next_token\n",
    "\n",
    "predict_next_token(\n",
    "    model, tokenizer=tok,\n",
    "    prompt=\"Eiffel Tower is located in the city of\",\n",
    "    k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Mary is visiting The Helix, Anton is visiting Shanghai International Film Festival, Marlys is visiting West Ham South. Mary is inDublin.\n",
      "Mary is visiting Battle of Crug Mawr, Gloria is visiting Battle of France, Daniel is visiting 2012 Summer Paralympics. Gloria is inBelgium.\n",
      "Rodger is visiting Family Life Radio, Juliet is visiting Nivelle Offensive, Mary is visiting Hubert H. Humphrey Metrodome. Rodger is inMichigan.\n",
      "William is visiting Cyclone Tracy, Brenda is visiting Halchidhoma, Kristin is visiting Regina Coeli. Kristin is inRome.\n",
      "Michael is visiting Pillsbury A Mill, James is visiting 1988 Summer Paralympics, Walter is visiting International Documentary Film Festival Amsterdam. Walter is inAmsterdam.\n",
      "Alice is vising the Big Ben, Bob is visiting the Statue of Liberty, Conrad is visiting the Taj Mahal. Alice is visiting the city of\n"
     ]
    }
   ],
   "source": [
    "query_prompt = \"Alice is vising the Big Ben, Bob is visiting the Statue of Liberty, Conrad is visiting the Taj Mahal. Alice is visiting the city of\"\n",
    "\n",
    "prompt = tok.bos_token + \"\\n\".join(icl_examples) + \"\\n\" + query_prompt\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('London', 0.6427210569381714, 4517),\n",
       "  ('Lond', 0.10462845116853714, 26682),\n",
       "  ('West', 0.06332361698150635, 3122),\n",
       "  ('West', 0.00995288323611021, 16128),\n",
       "  ('New', 0.008523721247911453, 1570)]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_token(\n",
    "    model = model, tokenizer = tok,\n",
    "    prompt = prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def untuple(x):\n",
    "    if isinstance(x, tuple):\n",
    "        return x[0]\n",
    "    return x\n",
    "\n",
    "\n",
    "def intervention(intervention_layer, intervene_at, patching_vector):\n",
    "    def edit_output(layer, output):\n",
    "        if layer != intervention_layer:\n",
    "            return output\n",
    "        untuple(output)[:, intervene_at] = patching_vector\n",
    "        return output\n",
    "\n",
    "    return edit_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing right vector (v)\n",
      "target_ids => 'Seattle'\n",
      "[([4], 'Tower')]\n",
      "Lookup index found: 4 | Sentence: 'Eiffel Tower is located in the city of' | Token: \"Tower\"\n",
      "[([14], 'Tower')]\n",
      "[([14], 'Tower')]\n",
      "[([14], 'Tower')]\n",
      "[([14], 'Tower')]\n",
      "[([14], 'Tower')]\n",
      "[([4], 'Tower')]\n",
      "Rewrite layer is 30\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 10.773 = 10.773 + 0.0 + 0.0 avg prob of [Seattle] 4.4857748434878886e-05\n",
      "loss 10.728 = 10.728 + 0.0 + 0.0 avg prob of [Seattle] 4.596297367243096e-05\n",
      "loss 10.666 = 10.666 + 0.0 + 0.0 avg prob of [Seattle] 4.7306060878327116e-05\n",
      "loss 10.567 = 10.565 + 0.001 + 0.0 avg prob of [Seattle] 5.0059268687618896e-05\n",
      "loss 10.401 = 10.399 + 0.001 + 0.001 avg prob of [Seattle] 5.602864985121414e-05\n",
      "loss 10.153 = 10.15 + 0.002 + 0.001 avg prob of [Seattle] 6.676112388959154e-05\n",
      "loss 9.821 = 9.816 + 0.003 + 0.001 avg prob of [Seattle] 8.498099487042055e-05\n",
      "loss 9.408 = 9.402 + 0.005 + 0.001 avg prob of [Seattle] 0.00011802320659626275\n",
      "loss 8.935 = 8.928 + 0.006 + 0.001 avg prob of [Seattle] 0.00017793822917155921\n",
      "loss 8.385 = 8.375 + 0.008 + 0.001 avg prob of [Seattle] 0.0002940593985840678\n",
      "loss 7.765 = 7.752 + 0.012 + 0.001 avg prob of [Seattle] 0.00052514678100124\n",
      "loss 7.142 = 7.124 + 0.016 + 0.002 avg prob of [Seattle] 0.0009486073977313936\n",
      "loss 6.556 = 6.531 + 0.023 + 0.002 avg prob of [Seattle] 0.0016678724205121398\n",
      "loss 6.004 = 5.969 + 0.032 + 0.002 avg prob of [Seattle] 0.0028649296145886183\n",
      "loss 5.471 = 5.424 + 0.045 + 0.002 avg prob of [Seattle] 0.00487664807587862\n",
      "loss 4.944 = 4.883 + 0.059 + 0.002 avg prob of [Seattle] 0.008313369005918503\n",
      "loss 4.414 = 4.338 + 0.074 + 0.002 avg prob of [Seattle] 0.014279639348387718\n",
      "loss 3.875 = 3.785 + 0.088 + 0.002 avg prob of [Seattle] 0.02477322332561016\n",
      "loss 3.329 = 3.226 + 0.1 + 0.002 avg prob of [Seattle] 0.04332154244184494\n",
      "loss 2.781 = 2.669 + 0.109 + 0.003 avg prob of [Seattle] 0.0757521390914917\n",
      "loss 2.245 = 2.125 + 0.117 + 0.003 avg prob of [Seattle] 0.13036806881427765\n",
      "loss 1.742 = 1.617 + 0.122 + 0.003 avg prob of [Seattle] 0.21548539400100708\n",
      "loss 1.356 = 1.232 + 0.122 + 0.003 avg prob of [Seattle] 0.3140207529067993\n",
      "loss 1.115 = 0.997 + 0.115 + 0.003 avg prob of [Seattle] 0.39419645071029663\n",
      "loss 0.917 = 0.805 + 0.109 + 0.003 avg prob of [Seattle] 0.47294020652770996\n",
      "loss 0.761 = 0.653 + 0.104 + 0.003 avg prob of [Seattle] 0.5449184775352478\n",
      "loss 0.638 = 0.535 + 0.1 + 0.003 avg prob of [Seattle] 0.6075974702835083\n",
      "loss 0.541 = 0.444 + 0.095 + 0.003 avg prob of [Seattle] 0.6607045531272888\n",
      "loss 0.464 = 0.372 + 0.089 + 0.003 avg prob of [Seattle] 0.7051619291305542\n",
      "loss 0.403 = 0.316 + 0.083 + 0.003 avg prob of [Seattle] 0.7422687411308289\n",
      "loss 0.353 = 0.272 + 0.078 + 0.003 avg prob of [Seattle] 0.7732851505279541\n",
      "loss 0.313 = 0.236 + 0.074 + 0.003 avg prob of [Seattle] 0.7993001937866211\n",
      "loss 0.28 = 0.206 + 0.071 + 0.003 avg prob of [Seattle] 0.8212097883224487\n",
      "loss 0.253 = 0.182 + 0.068 + 0.003 avg prob of [Seattle] 0.8397433161735535\n",
      "loss 0.231 = 0.162 + 0.066 + 0.003 avg prob of [Seattle] 0.8554932475090027\n",
      "Init norm 129.30548095703125 | Delta norm 96.97911071777344 | Target norm 145.71743774414062\n"
     ]
    }
   ],
   "source": [
    "from memit.compute_z import compute_z\n",
    "from memit.memit_hparams import MEMITHyperParams\n",
    "from memit.memit_main import get_context_templates\n",
    "\n",
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} is located in the city of\",\n",
    "        \"subject\": \"Eiffel Tower\",\n",
    "        \"target_new\": {\"str\": \"Seattle\"},\n",
    "    },\n",
    "    # {\n",
    "    #     \"prompt\": \"{} is located in the city of\",\n",
    "    #     \"subject\": \"Big Ben\",\n",
    "    #     \"target_new\": {\"str\": \"Paris\"},\n",
    "    # },\n",
    "]\n",
    "\n",
    "context_templates = get_context_templates(\n",
    "    model, tok\n",
    ")\n",
    "\n",
    "hparam_root = \"../hparams/MEMIT\"\n",
    "hparam_file = model.config._name_or_path.replace(\"/\",\"_\") + \".json\"\n",
    "hparam_file = os.path.join(hparam_root, hparam_file)\n",
    "hparams = json.load(open(hparam_file, \"r\"))\n",
    "hparams = MEMITHyperParams(**hparams)\n",
    "\n",
    "layer_no = 30\n",
    "layer_name = hparams.layer_module_tmp.format(layer_no)\n",
    "\n",
    "z = compute_z(\n",
    "    model, tok,\n",
    "    request=request[0],\n",
    "    hparams=hparams,\n",
    "    layer = layer_no,\n",
    "    context_templates=context_templates,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from memit.extra_utils import find_token_range\n",
    "\n",
    "# prompt = request[0][\"prompt\"].format(request[0][\"subject\"])\n",
    "prompt = \"{}, which is in\".format(request[0][\"subject\"])\n",
    "subject = request[0][\"subject\"]\n",
    "\n",
    "tokenized = tok(prompt, return_offsets_mapping=True, return_tensors=\"pt\").to(model.device)\n",
    "offset_mapping = tokenized.pop(\"offset_mapping\")\n",
    "\n",
    "subject_start, subject_end = find_token_range(\n",
    "    prompt, subject, tokenizer=tok, offset_mapping=offset_mapping[0]\n",
    ")\n",
    "subject_start, subject_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tensor(0.4106, device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Seattle tensor(0.1990, device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Paris tensor(0.0733, device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "fact tensor(0.0448, device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "France tensor(0.0248, device='cuda:0', grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "with nethook.TraceDict(\n",
    "    model,\n",
    "    layers = [layer_name],\n",
    "    edit_output=intervention(layer_name, subject_end-1, z),\n",
    ") as traces:\n",
    "    output = model(**tokenized)\n",
    "\n",
    "next_token_probs = output.logits[:, -1].float().softmax(dim=-1)\n",
    "next_token_topk = next_token_probs.topk(dim=-1, k=5)\n",
    "for t, logit in zip(next_token_topk.indices.squeeze(), next_token_topk.values.squeeze()):\n",
    "    print(tok.decode(t), logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Mary is visiting The Helix, Anton is visiting Shanghai International Film Festival, Marlys is visiting West Ham South. Mary is inDublin.\n",
      "Mary is visiting Battle of Crug Mawr, Gloria is visiting Battle of France, Daniel is visiting 2012 Summer Paralympics. Gloria is inBelgium.\n",
      "Rodger is visiting Family Life Radio, Juliet is visiting Nivelle Offensive, Mary is visiting Hubert H. Humphrey Metrodome. Rodger is inMichigan.\n",
      "William is visiting Cyclone Tracy, Brenda is visiting Halchidhoma, Kristin is visiting Regina Coeli. Kristin is inRome.\n",
      "Michael is visiting Pillsbury A Mill, James is visiting 1988 Summer Paralympics, Walter is visiting International Documentary Film Festival Amsterdam. Walter is inAmsterdam.\n",
      "Alice is vising Big Ben, Bob is visiting Eiffel Tower , Conrad is visiting Taj Mahal. Alice is visiting the city of\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(227, 'Tower')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_prompt = \"Alice is vising Big Ben, Bob is visiting Eiffel Tower , Conrad is visiting Taj Mahal. Alice is visiting the city of\"\n",
    "\n",
    "prompt = tok.bos_token + \"\\n\".join(icl_examples) + \"\\n\" + query_prompt\n",
    "\n",
    "print(prompt)\n",
    "subject = \"Eiffel Tower\"\n",
    "\n",
    "tokenized = tok(prompt, return_offsets_mapping=True, return_tensors=\"pt\").to(model.device)\n",
    "offset_mapping = tokenized.pop(\"offset_mapping\")\n",
    "\n",
    "subject_start, subject_end = find_token_range(\n",
    "    prompt, subject, tokenizer=tok, offset_mapping=offset_mapping[0]\n",
    ")\n",
    "\n",
    "subject_end-1, tok.decode(tokenized[\"input_ids\"][0][subject_end-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seattle tensor(0.4048, device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "London tensor(0.3563, device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "West tensor(0.0352, device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Lond tensor(0.0324, device='cuda:0', grad_fn=<UnbindBackward0>)\n",
      "Washington tensor(0.0070, device='cuda:0', grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "with nethook.TraceDict(\n",
    "    model,\n",
    "    layers = [layer_name],\n",
    "    edit_output=intervention(layer_name, subject_end-1, z),\n",
    ") as traces:\n",
    "    output = model(**tokenized)\n",
    "\n",
    "next_token_probs = output.logits[:, -1].float().softmax(dim=-1)\n",
    "next_token_topk = next_token_probs.topk(dim=-1, k=5)\n",
    "for t, logit in zip(next_token_topk.indices.squeeze(), next_token_topk.values.squeeze()):\n",
    "    print(tok.decode(t), logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
